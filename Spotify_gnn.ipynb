{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from os.path import isfile, join\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import dgl\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "from typing import Optional, Union\n",
    "\n",
    "import torch \n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.nn import Embedding, ModuleList\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_geometric.data import Data, HeteroData\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import HGTConv, Linear\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch_geometric.typing import Adj, OptTensor, SparseTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 12345\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here we define classes for the data that we are going to load. The data is stored in JSON files, each\n",
    "which contain playlists, which themselves contain tracks. Thus, we define three classes: \n",
    "  Track       --> contains information for a specific track (its id, name, etc.)\n",
    "  Playlist    --> contains information for a specific playlist (its id, name, etc. as well as a list of Tracks)\n",
    "  JSONFile    --> contains the loaded json file and stores a dictionary of all of the Playlists \n",
    "  Artists     --> contains information on the artist for a specific track(its id, name, etc.)\n",
    "\n",
    "\"\"\"\n",
    "class Artist:\n",
    "  \n",
    "  def __init__(self, track_dict, playlist):\n",
    "    self.uri = track_dict[\"artist_uri\"]\n",
    "    self.name = track_dict[\"artist_name\"]\n",
    "    self.track_uri = track_dict[\"track_uri\"]\n",
    "    self.track_name = track_dict[\"track_name\"]\n",
    "    self.playlist = playlist\n",
    "\n",
    "    def __str__(self):\n",
    "      return f\"Artist {self.uri} called {self.name} composed {self.track_uri} ({self.track_name}) in playlist {self.playlist}.\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "      return f\"Artist {self.uri}\"\n",
    "      \n",
    "class Track: \n",
    "  \"\"\" \n",
    "  Simple class for a track, containing its attributes: \n",
    "    1. URI (a unique id)\n",
    "    2. Name\n",
    "    3. Artist info (URI and name)\n",
    "    4. Parent playlist\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, track_dict, playlist):\n",
    "    self.uri = track_dict[\"track_uri\"]\n",
    "    self.name = track_dict[\"track_name\"]\n",
    "    self.artist_uri = track_dict[\"artist_uri\"]\n",
    "    self.artist_name = track_dict[\"artist_name\"]\n",
    "    self.playlist = playlist\n",
    "  \n",
    "  def __str__(self):\n",
    "    return f\"Track {self.uri} called {self.name} by {self.artist_uri} ({self.artist_name}) in playlist {self.playlist}.\"\n",
    "  \n",
    "  def __repr__(self):\n",
    "    return f\"Track {self.uri}\"\n",
    "\n",
    "class Playlist: \n",
    "  \"\"\" \n",
    "  Simple class for a playlist, containing its attributes: \n",
    "    1. Name (playlist and its associated index)\n",
    "    2. Title (playlist title in the Spotify dataset)\n",
    "    3. Loaded dictionary from the raw json for the playlist\n",
    "    4. Dictionary of tracks (track_uri : Track), populated by .load_tracks()\n",
    "    5. List of artists uris\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, json_data, index):\n",
    "\n",
    "    self.name = f\"playlist_{index}\"\n",
    "    self.title = json_data[\"name\"]\n",
    "    self.data = json_data\n",
    "\n",
    "    self.tracks = {}\n",
    "    self.artists = {}\n",
    "  \n",
    "  def load_tracks(self):\n",
    "    \"\"\" Call this function to load all of the tracks in the json data for the playlist.\"\"\"\n",
    "\n",
    "    tracks_list = self.data[\"tracks\"]\n",
    "    self.tracks = {x[\"track_uri\"] : Track(x, self.name) for x in tracks_list}\n",
    "    self.artists = {x[\"artist_uri\"] : Artist(x,self.name) for x in tracks_list}\n",
    "\n",
    "  def __str__(self):\n",
    "    return f\"Playlist {self.name} with {len(self.tracks)} tracks loaded.\"\n",
    "  \n",
    "  def __repr__(self):\n",
    "    return f\"Playlist {self.name}\"\n",
    "\n",
    "class JSONFile: \n",
    "  \"\"\" \n",
    "  Simple class for a JSON file, containing its attributes: \n",
    "    1. File Name \n",
    "    2. Index to begin numbering playlists at \n",
    "    3. Loaded dictionary from the raw json for the full file\n",
    "    4. Dictionary of playlists (name : Playlist), populated by .process_file()\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, data_path, file_name, start_index):\n",
    "\n",
    "    self.file_name = file_name \n",
    "    self.start_index = start_index\n",
    "\n",
    "    with open(join(data_path, file_name)) as json_file:\n",
    "      json_data = json.load(json_file)\n",
    "    self.data = json_data \n",
    "\n",
    "    self.playlists = {}\n",
    "\n",
    "  def process_file(self):\n",
    "    \"\"\" Call this function to load all of the playlists in the json data.\"\"\"\n",
    "\n",
    "    for i, playlist_json in enumerate(self.data[\"playlists\"]):\n",
    "      playlist = Playlist(playlist_json, self.start_index + i)\n",
    "      playlist.load_tracks()\n",
    "      self.playlists[playlist.name] = playlist\n",
    "\n",
    "  def __str__(self):\n",
    "    return f\"JSON {self.file_name} has {len(self.playlists)} playlists loaded.\"\n",
    "  \n",
    "  def __repr__(self):\n",
    "    return self.file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files processed: 100%|██████████| 30/30 [00:04<00:00,  6.07files/s]\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path('./Spotify_playlists_101')\n",
    "N_FILES_TO_USE = 30\n",
    "\n",
    "file_names = sorted(os.listdir(DATA_PATH))\n",
    "file_names_to_use = file_names[:N_FILES_TO_USE]\n",
    "\n",
    "n_playlists = 0 \n",
    "\n",
    "# load each json file, and store it in a list of files\n",
    "JSONs = []\n",
    "for file_name in tqdm(file_names_to_use, desc='Files processed: ', unit='files', total=len(file_names_to_use)):\n",
    "  json_file = JSONFile(DATA_PATH, file_name, n_playlists)\n",
    "  json_file.process_file()\n",
    "  n_playlists += len(json_file.playlists)\n",
    "  JSONs.append(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 187.37it/s]\n"
     ]
    }
   ],
   "source": [
    "playlist_data = {}\n",
    "playlists = []\n",
    "tracks = []\n",
    "artists = []\n",
    "\n",
    "# build list of playlists, tracks, artists\n",
    "for json_file in tqdm(JSONs): \n",
    "  playlists += [p.name for p in json_file.playlists.values()]\n",
    "  tracks += [track.uri for playlist in json_file.playlists.values() for track in list(playlist.tracks.values())]\n",
    "  artists += [artist.uri for playlist in json_file.playlists.values() for artist in list(playlist.artists.values())]\n",
    "  playlist_data = playlist_data | json_file.playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build unique list of tracks , artists\n",
    "tracks = list(set(tracks))\n",
    "artists = list(set(artists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Playlists:30000, No of tracks: 339283, No of artists:62380\n"
     ]
    }
   ],
   "source": [
    "print(f\"No of Playlists:{len(playlists)}, No of tracks: {len(tracks)}, No of artists:{len(artists)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a track-artist key-value pair\n",
    "track_artist = {}\n",
    "for json_files in JSONs:\n",
    "      for playlist in json_files.playlists.values():\n",
    "            for track in playlist.tracks.values():\n",
    "                  if track.uri not in track_artist.keys():\n",
    "                        track_artist[track.uri] = track.artist_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heterogenous graph from the data\n",
    "playlists_2idx = {playlist: idx for idx, playlist in enumerate(playlists)}\n",
    "tracks_2idx = {track: idx for idx, track in enumerate(tracks)}\n",
    "artists_2idx = {artist: idx for idx, artist in enumerate(artists)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_track_edges = []\n",
    "for p_name, playlist in playlist_data.items(): \n",
    "  playlist_track_edges += [(p_name, t) for t in playlist.tracks]\n",
    "playlist_artist_edges = []\n",
    "for p_name, playlist in playlist_data.items():\n",
    "  playlist_artist_edges += [(p_name, a) for a in playlist.artists]\n",
    "track_artist_edges = []\n",
    "for track, artist in track_artist.items():\n",
    "  track_artist_edges.append((track, artist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_track_edges_idx = tuple(torch.tensor([playlists_2idx[pl], tracks_2idx[track]]) for pl, track in playlist_track_edges)\n",
    "playlist_artist_edges_idx = tuple(torch.tensor([playlists_2idx[pl], artists_2idx[artist]]) for pl, artist in playlist_artist_edges)\n",
    "track_artist_edges_idx = tuple(torch.tensor([tracks_2idx[track], artists_2idx[artist]]) for track, artist in track_artist_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_track_edges_idx = tuple(torch.cat([t[i].unsqueeze(0) for t in playlist_track_edges_idx]) for i in range(len(playlist_track_edges_idx[0])))\n",
    "playlist_artist_edges_idx = tuple(torch.cat([t[i].unsqueeze(0) for t in playlist_artist_edges_idx]) for i in range(len(playlist_artist_edges_idx[0])))\n",
    "track_artist_edges_idx = tuple(torch.cat([t[i].unsqueeze(0) for t in track_artist_edges_idx]) for i in range(len(track_artist_edges_idx[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  playlist={\n",
      "    node_id=[30000],\n",
      "    x=[30000, 128],\n",
      "  },\n",
      "  track={\n",
      "    node_id=[339283],\n",
      "    x=[339283, 64],\n",
      "  },\n",
      "  artist={\n",
      "    node_id=[62380],\n",
      "    x=[62380, 32],\n",
      "  },\n",
      "  (playlist, contains_track, track)={ edge_index=[2, 1985474] },\n",
      "  (playlist, contains_artist, artist)={ edge_index=[2, 1147878] },\n",
      "  (track, by, artist)={ edge_index=[2, 339283] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Convert data to Hetero Data object with  Pyg Library , see of we can create a subgraph with lesser nodes\n",
    "hetero_graph = HeteroData()\n",
    "\n",
    "hetero_graph[\"playlist\"].node_id = torch.arange(len(playlists))\n",
    "hetero_graph[\"track\"].node_id = torch.arange(len(tracks))\n",
    "hetero_graph[\"artist\"].node_id = torch.arange(len(artists))\n",
    "\n",
    "hetero_graph[\"playlist\"].x = torch.randn(len(playlists), 128)\n",
    "hetero_graph[\"track\"].x = torch.randn(len(tracks), 64)\n",
    "hetero_graph[\"artist\"].x = torch.randn(len(artists), 32)\n",
    "\n",
    "\n",
    "hetero_graph['playlist', 'contains_track', 'track'].edge_index = torch.stack(playlist_track_edges_idx)\n",
    "hetero_graph['playlist', 'contains_artist', 'artist'].edge_index = torch.stack(playlist_artist_edges_idx)\n",
    "hetero_graph['track', 'by', 'artist'].edge_index = torch.stack(track_artist_edges_idx)\n",
    "\n",
    "\n",
    "\n",
    "print(hetero_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# hetero_graph = hetero_graph.to(device)\n",
    "hetero_graph = T.ToUndirected()(hetero_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training (80%), validation (10%), and testing edges (10%)\n",
    "# In training edges, 70% used for message passing , 30% edges for supervision\n",
    "\n",
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    disjoint_train_ratio=0.3,\n",
    "    neg_sampling_ratio=2.0,\n",
    "    add_negative_train_samples=False,\n",
    "    edge_types=[('playlist', 'contains_track', 'track')],\n",
    "    rev_edge_types=[('track', 'rev_contains_track', 'playlist')], \n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(hetero_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGT(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_heads, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin_dict = torch.nn.ModuleDict()\n",
    "        for node_type in hetero_graph.node_types:\n",
    "            self.lin_dict[node_type] = Linear(-1, hidden_channels)\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HGTConv(hidden_channels, hidden_channels, hetero_graph.metadata(),\n",
    "                           num_heads)\n",
    "            self.convs.append(conv)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = {\n",
    "            node_type: self.lin_dict[node_type](x).relu_()\n",
    "            for node_type, x in x_dict.items()\n",
    "        }\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "\n",
    "        return x_dict\n",
    "\n",
    "class Classifier(torch.nn.Module):\n",
    "\n",
    "    def forward(self, x_dict, edge_label_index):\n",
    "        # Get Node embeddings to compute edge feature\n",
    "        edge_feat_playlist = x_dict[\"playlist\"][edge_label_index[0]]\n",
    "        edge_feat_track = x_dict[\"track\"][edge_label_index[1]]\n",
    "\n",
    "        # Apply dot-product to get a prediction per supervision edge:\n",
    "        return (edge_feat_playlist * edge_feat_track).sum(dim=-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_channels, num_heads, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rgnn = HGT(hidden_channels, num_heads, num_layers)\n",
    "\n",
    "        self.classifier = Classifier()\n",
    "\n",
    "    def forward(self, data):\n",
    "\n",
    "        x_dict = self.rgnn(data.x_dict, data.edge_index_dict)\n",
    "        pred = self.classifier(x_dict, data['playlist', 'contains_track', 'track'].edge_label_index)\n",
    "\n",
    "        return pred\n",
    "\n",
    "model = Model(hidden_channels=64, num_heads=2, num_layers=1)\n",
    "model = model.to(device)\n",
    "\n",
    "with torch.no_grad():  # Initialize lazy modules.\n",
    "    out = model(train_data.to(device))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = NeighborLoader(\n",
    "#     train_data,\n",
    "#     # Sample 512 nodes per type and per iteration for 4 iterations\n",
    "#     num_neighbors=[128] * 2,\n",
    "#     # Use a batch size of 128 for sampling training nodes of type paper\n",
    "#     batch_size=128,\n",
    "#     input_nodes='playlist',\n",
    "# )\n",
    "# val_loader = NeighborLoader(\n",
    "#     val_data,\n",
    "#     # Sample 512 nodes per type and per iteration for 4 iterations\n",
    "#     num_neighbors=[128] * 2,\n",
    "#     # Use a batch size of 128 for sampling training nodes of type paper\n",
    "#     batch_size=128,\n",
    "#     input_nodes='playlist',\n",
    "# )\n",
    "\n",
    "# val_loader = HGTLoader(\n",
    "#     val_data,\n",
    "#     # Sample 512 nodes per type and per iteration for 4 iterations\n",
    "#     num_samples={key: [512] * 4 for key in val_data.node_types},\n",
    "#     # Use a batch size of 128 for sampling training nodes of type paper\n",
    "#     batch_size=128,\n",
    "#     input_nodes=('playlist'),\n",
    "# )\n",
    "# train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "# val_loader = DataLoader(val_data, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: 0.6943, Val Loss: 0.2488, Val AUC: 0.4889\n",
      "Epoch: 002, Train Loss: 0.6196, Val Loss: 0.2405, Val AUC: 0.4952\n",
      "Epoch: 003, Train Loss: 0.5460, Val Loss: 0.2368, Val AUC: 0.5020\n",
      "Epoch: 004, Train Loss: 0.4722, Val Loss: 0.2391, Val AUC: 0.5095\n",
      "Epoch: 005, Train Loss: 0.3975, Val Loss: 0.2495, Val AUC: 0.5177\n",
      "Epoch: 006, Train Loss: 0.3217, Val Loss: 0.2716, Val AUC: 0.5268\n",
      "Epoch: 007, Train Loss: 0.2458, Val Loss: 0.3109, Val AUC: 0.5369\n",
      "Epoch: 008, Train Loss: 0.1723, Val Loss: 0.3757, Val AUC: 0.5482\n",
      "Epoch: 009, Train Loss: 0.1062, Val Loss: 0.4770, Val AUC: 0.5606\n",
      "Epoch: 010, Train Loss: 0.0564, Val Loss: 0.6267, Val AUC: 0.5734\n",
      "Epoch: 011, Train Loss: 0.0361, Val Loss: 0.8200, Val AUC: 0.5846\n",
      "Epoch: 012, Train Loss: 0.0559, Val Loss: 0.9942, Val AUC: 0.5893\n",
      "Epoch: 013, Train Loss: 0.0974, Val Loss: 1.0700, Val AUC: 0.5870\n",
      "Epoch: 014, Train Loss: 0.1178, Val Loss: 1.0455, Val AUC: 0.5804\n"
     ]
    }
   ],
   "source": [
    "def train(data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    data = data.to(device)\n",
    "    pred = model(data)\n",
    "\n",
    "    ground_truth = data['playlist', 'contains_track', 'track'].edge_label\n",
    "    # loss = F.binary_cross_entropy_with_logits(pred, ground_truth)\n",
    "    loss = F.mse_loss(pred, ground_truth)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return float(loss)\n",
    "\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    data = data.to(device)\n",
    "    with torch.no_grad():\n",
    "     pred = model(data)\n",
    "    ground_truth = data['playlist', 'contains_track', 'track'].edge_label\n",
    "\n",
    "    # loss = F.binary_cross_entropy_with_logits(pred, ground_truth)\n",
    "    loss = F.mse_loss(pred, ground_truth)\n",
    "    auc = roc_auc_score(ground_truth.detach().cpu().numpy(), pred.detach().cpu().numpy())\n",
    "    return float(loss), auc\n",
    "\n",
    "for epoch in range(1, 15):\n",
    "\n",
    "    train_loss = train(train_data)\n",
    "    val_loss, auc= test(val_data)\n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val AUC: {auc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
